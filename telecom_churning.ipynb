{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a617556-27f5-462f-8875-98c44ca67d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34de13f-bf6f-47a9-b10a-6225fb1c16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Churn  AccountWeeks  ContractRenewal  DataPlan  DataUsage  CustServCalls  \\\n",
      "0      0           128                1         1        2.7              1   \n",
      "1      0           107                1         1        3.7              1   \n",
      "2      0           137                1         0        0.0              0   \n",
      "3      0            84                0         0        0.0              2   \n",
      "4      0            75                0         0        0.0              3   \n",
      "\n",
      "   DayMins  DayCalls  MonthlyCharge  OverageFee  RoamMins  \n",
      "0    265.1       110           89.0        9.87      10.0  \n",
      "1    161.6       123           82.0        9.78      13.7  \n",
      "2    243.4       114           52.0        6.06      12.2  \n",
      "3    299.4        71           57.0        3.10       6.6  \n",
      "4    166.7       113           41.0        7.42      10.1  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('telecom_churn.csv')  # Replace 'your_file.csv' with your actual file name or path\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00682440-09fc-4a22-b2b4-7d093e9d8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder  # For scaling and encoding\n",
    "from sklearn.compose import ColumnTransformer  # For applying transformations to columns\n",
    "from sklearn.pipeline import Pipeline  # For creating a machine learning pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33e46fb9-e8ee-4315-811f-1fa06c1157a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Churn            3333 non-null   int64  \n",
      " 1   AccountWeeks     3333 non-null   int64  \n",
      " 2   ContractRenewal  3333 non-null   int64  \n",
      " 3   DataPlan         3333 non-null   int64  \n",
      " 4   DataUsage        3333 non-null   float64\n",
      " 5   CustServCalls    3333 non-null   int64  \n",
      " 6   DayMins          3333 non-null   float64\n",
      " 7   DayCalls         3333 non-null   int64  \n",
      " 8   MonthlyCharge    3333 non-null   float64\n",
      " 9   OverageFee       3333 non-null   float64\n",
      " 10  RoamMins         3333 non-null   float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 286.6 KB\n",
      "None\n",
      "\n",
      "Data Description:\n",
      "             Churn  AccountWeeks  ContractRenewal     DataPlan    DataUsage  \\\n",
      "count  3333.000000   3333.000000      3333.000000  3333.000000  3333.000000   \n",
      "mean      0.144914    101.064806         0.903090     0.276628     0.816475   \n",
      "std       0.352067     39.822106         0.295879     0.447398     1.272668   \n",
      "min       0.000000      1.000000         0.000000     0.000000     0.000000   \n",
      "25%       0.000000     74.000000         1.000000     0.000000     0.000000   \n",
      "50%       0.000000    101.000000         1.000000     0.000000     0.000000   \n",
      "75%       0.000000    127.000000         1.000000     1.000000     1.780000   \n",
      "max       1.000000    243.000000         1.000000     1.000000     5.400000   \n",
      "\n",
      "       CustServCalls      DayMins     DayCalls  MonthlyCharge   OverageFee  \\\n",
      "count    3333.000000  3333.000000  3333.000000    3333.000000  3333.000000   \n",
      "mean        1.562856   179.775098   100.435644      56.305161    10.051488   \n",
      "std         1.315491    54.467389    20.069084      16.426032     2.535712   \n",
      "min         0.000000     0.000000     0.000000      14.000000     0.000000   \n",
      "25%         1.000000   143.700000    87.000000      45.000000     8.330000   \n",
      "50%         1.000000   179.400000   101.000000      53.500000    10.070000   \n",
      "75%         2.000000   216.400000   114.000000      66.200000    11.770000   \n",
      "max         9.000000   350.800000   165.000000     111.300000    18.190000   \n",
      "\n",
      "          RoamMins  \n",
      "count  3333.000000  \n",
      "mean     10.237294  \n",
      "std       2.791840  \n",
      "min       0.000000  \n",
      "25%       8.500000  \n",
      "50%      10.300000  \n",
      "75%      12.100000  \n",
      "max      20.000000  \n",
      "Preprocessing steps 1 to 7 completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv('telecom_churn.csv')  # Updated file name\n",
    "\n",
    "# Step 2: Inspect the data\n",
    "print(\"Data Information:\")\n",
    "print(df.info())  # Display information about the DataFrame\n",
    "print(\"\\nData Description:\")\n",
    "print(df.describe())  # Display basic statistics for numerical columns\n",
    "\n",
    "# Step 3: Handle missing values\n",
    "# Fill missing categorical values with mode\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().any():  # Check if there are any missing values\n",
    "        mode_value = df[col].mode()\n",
    "        if not mode_value.empty:  # Check if mode is not empty\n",
    "            df[col].fillna(mode_value[0], inplace=True)  # Fill with the mode\n",
    "\n",
    "# Fill missing numerical values with mean (or median, depending on your choice)\n",
    "for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if df[col].isnull().any():  # Check if there are any missing values\n",
    "        mean_value = df[col].mean()  # Calculate mean\n",
    "        df[col].fillna(mean_value, inplace=True)  # Fill with the mean\n",
    "\n",
    "# Step 4: Data cleaning\n",
    "df.drop_duplicates(inplace=True)  # Remove duplicate rows\n",
    "\n",
    "# Step 5: Feature engineering (example)\n",
    "# Example: Create a new feature based on existing ones\n",
    "# df['new_feature'] = df['existing_feature'] * 2  # Uncomment and modify as needed\n",
    "\n",
    "# Step 6: Encoding categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()  # Identify categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()  # Identify numerical columns\n",
    "\n",
    "# Step 7: Feature scaling\n",
    "# Create a ColumnTransformer to apply transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  # Scale numerical features\n",
    "        ('cat', OneHotEncoder(), categorical_cols)   # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "# The preprocessor can be used later in a pipeline for model training\n",
    "print(\"Preprocessing steps 1 to 7 completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bbcc08f-0900-488c-918c-70602239404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Features (X_train): (2666, 10)\n",
      "Shape of Features (X_test): (667, 10)\n",
      "Shape of Target (y_train): (2666,)\n",
      "Shape of Target (y_test): (667,)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Splitting the Data\n",
    "# Check if the target variable exists\n",
    "if 'ContractRenewal' not in df.columns:  # Replace 'ContractRenewal' with your actual target column name\n",
    "    raise ValueError(\"Target variable 'ContractRenewal' not found in the DataFrame.\")\n",
    "\n",
    "X = df.drop('ContractRenewal', axis=1)  # Features (replace 'ContractRenewal' with your actual target column name)\n",
    "y = df['ContractRenewal']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the resulting datasets\n",
    "print(\"\\nShape of Features (X_train):\", X_train.shape)\n",
    "print(\"Shape of Features (X_test):\", X_test.shape)\n",
    "print(\"Shape of Target (y_train):\", y_train.shape)\n",
    "print(\"Shape of Target (y_test):\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea15e1-8e88-4a4d-af7f-3f597876f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # Import a machine learning model\n",
    "\n",
    "# Step 9: Create a Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Include the preprocessor created in previous steps\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Replace with your chosen model\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Pipeline created and model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449082c-d398-4574-9084-5bf5884ea4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Pipeline created and model fitted successfully.\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Step 12: Save the model for future use\n",
    "joblib.dump(pipeline, 'random_forest_pipeline.pkl')\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
